# min-speak Technical Documentation

> **Last Updated:** December 24, 2025  
> **Version:** 1.0  
> **Maintainer:** Development Team

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture & Design Patterns](#architecture--design-patterns)
3. [Folder Structure](#folder-structure)
4. [Data Flow & System Workflows](#data-flow--system-workflows)
5. [Component Architecture](#component-architecture)
6. [State Management](#state-management)
7. [API Routes & Services](#api-routes--services)
8. [Type System](#type-system)
9. [Key Dependencies](#key-dependencies)
10. [Development Guidelines](#development-guidelines)
11. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Project Overview

### What is min-speak?

**min-speak** is a Next.js-based language learning application that helps Vietnamese speakers practice English through **real-time voice conversations** with an AI agent. The app provides:

- **Live voice chat** with ElevenLabs Conversational AI
- **Detailed conversation analysis** using Google Gemini AI
- **Two interaction modes:** Chat view (with message history) and Immersive view (fullscreen avatar)
- **Personalized feedback** on grammar, vocabulary, and pronunciation

### Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Framework** | Next.js 16 (App Router) | React-based full-stack framework |
| **Language** | TypeScript 5 | Type-safe development |
| **AI - Conversation** | ElevenLabs Conversational AI | Real-time voice interaction |
| **AI - Analysis** | Google Gemini 2.0 Flash | Conversation analysis & feedback |
| **UI Framework** | Tailwind CSS + shadcn/ui | Responsive, accessible components |
| **Animation** | Framer Motion | Smooth avatar animations |
| **Deployment** | Vercel | Serverless hosting with edge functions |

---

## ğŸ—ï¸ Architecture & Design Patterns

### 1. **Layered Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRESENTATION LAYER              â”‚
â”‚   (Components, Screens, UI)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         APPLICATION LAYER               â”‚
â”‚   (Hooks, State Management)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         BUSINESS LOGIC LAYER            â”‚
â”‚   (Services, Utilities)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         DATA LAYER                      â”‚
â”‚   (Types, Config, Constants)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         INFRASTRUCTURE LAYER            â”‚
â”‚   (API Routes, External Services)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Key Design Patterns**

#### **State Machine Pattern** (`app/page.tsx`)
The main page uses a finite state machine to control screen transitions:

```typescript
type AppScreen = "landing" | "modeSelection" | "conversation" | "analysis"
const [currentScreen, setCurrentScreen] = useState<AppScreen>("landing")
```

**Flow:**
```
landing â†’ modeSelection â†’ conversation â†’ analysis â†’ landing
```

#### **Service Layer Pattern** (`lib/services/`)
Business logic is separated into dedicated services:
- `gemini.service.ts` - AI conversation analysis
- `elevenlabs.service.ts` - Voice authentication
- `conversation.service.ts` - Message formatting & transformation

#### **Facade Pattern** (API Routes)
API routes act as facades, delegating to services:

```typescript
// app/api/conversation-analysis/route.ts
export async function POST(request) {
  const data = await request.json()
  const result = await analyzeConversation(data) // â† Delegates to service
  return Response.json(result)
}
```

#### **Hook Pattern** (Custom Hooks)
Complex logic encapsulated in custom hooks:
- `useElevenLabsConversation` - Manages entire voice conversation lifecycle

#### **Shared Component Pattern** (`components/shared/`)
Reusable UI components to enforce DRY:
- `ConnectionStatusBadge` - Connection status indicator
- `AnalysisLoadingScreen` - Loading state UI

---

## ğŸ“ Folder Structure

```
min-speak/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx                  # â­ Main app (state machine)
â”‚   â”œâ”€â”€ layout.tsx                # Root layout with fonts
â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â””â”€â”€ api/                      # API Routes (Backend)
â”‚       â”œâ”€â”€ conversation-analysis/
â”‚       â”‚   â””â”€â”€ route.ts          # POST: Analyze conversation
â”‚       â””â”€â”€ elevenlabs-signed-url/
â”‚           â””â”€â”€ route.ts          # GET: Generate signed URL
â”‚
â”œâ”€â”€ components/                   # React Components
â”‚   â”œâ”€â”€ ui/                       # shadcn/ui primitives
â”‚   â”œâ”€â”€ shared/                   # Shared reusable components
â”‚   â”‚   â”œâ”€â”€ connection-status-badge.tsx
â”‚   â”‚   â””â”€â”€ analysis-loading-screen.tsx
â”‚   â”œâ”€â”€ hero-landing.tsx          # Landing screen
â”‚   â”œâ”€â”€ mode-selection-modal.tsx  # Chat vs Immersive selection
â”‚   â”œâ”€â”€ live-chat-conversation.tsx # Main conversation wrapper
â”‚   â”œâ”€â”€ chat-mode-view.tsx        # Chat mode UI
â”‚   â”œâ”€â”€ immersive-mode-view.tsx   # Immersive mode UI
â”‚   â”œâ”€â”€ conversation-analysis-screen.tsx # Results screen
â”‚   â””â”€â”€ avatar.tsx                # Animated avatar component
â”‚
â”œâ”€â”€ hooks/                        # Custom React Hooks
â”‚   â””â”€â”€ useElevenLabsConversation.ts # Voice conversation logic
â”‚
â”œâ”€â”€ lib/                          # Core Business Logic
â”‚   â”œâ”€â”€ types/                    # TypeScript Type Definitions
â”‚   â”‚   â”œâ”€â”€ conversation.ts       # Message, ConversationAnalysis
â”‚   â”‚   â”œâ”€â”€ gemini.ts             # Gemini API types
â”‚   â”‚   â”œâ”€â”€ api.ts                # API response types
â”‚   â”‚   â””â”€â”€ index.ts              # Barrel exports
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                   # Configuration Files
â”‚   â”‚   â”œâ”€â”€ gemini.ts             # Gemini models, prompts, fallbacks
â”‚   â”‚   â”œâ”€â”€ constants.ts          # App-wide constants
â”‚   â”‚   â””â”€â”€ ui-constants.ts       # Animation timings, delays
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # Business Logic Services
â”‚   â”‚   â”œâ”€â”€ gemini.service.ts     # Gemini API interaction
â”‚   â”‚   â”œâ”€â”€ elevenlabs.service.ts # ElevenLabs API calls
â”‚   â”‚   â””â”€â”€ conversation.service.ts # Message formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Utility Functions
â”‚   â”‚   â”œâ”€â”€ cn.ts                 # Tailwind class merger
â”‚   â”‚   â”œâ”€â”€ validators.ts         # Input validation
â”‚   â”‚   â”œâ”€â”€ formatters.ts         # Text formatting
â”‚   â”‚   â””â”€â”€ array-helpers.ts      # Array utilities
â”‚   â”‚
â”‚   â””â”€â”€ api/                      # API Helpers
â”‚       â”œâ”€â”€ handlers.ts           # API response builders
â”‚       â””â”€â”€ error-handler.ts      # Error handling utilities
â”‚
â”œâ”€â”€ public/                       # Static Assets
â”‚   â”œâ”€â”€ avatar/                   # Avatar GIFs (idle, listening, speaking)
â”‚   â”œâ”€â”€ background/               # Background images per screen
â”‚   â””â”€â”€ worldavatar/              # Immersive mode videos
â”‚
â””â”€â”€ [config files]                # Next.js, TypeScript, Tailwind configs
```

### **Critical Files Explained**

| File | Purpose | Lines | Complexity |
|------|---------|-------|------------|
| `app/page.tsx` | Main app state machine, screen orchestration | 124 | High |
| `hooks/useElevenLabsConversation.ts` | Voice conversation lifecycle management | 158 | High |
| `components/conversation-analysis-screen.tsx` | Display AI feedback results | 200 | Medium |
| `lib/services/gemini.service.ts` | Gemini API calls & analysis | 48 | Medium |
| `lib/config/gemini.ts` | AI prompts & model configurations | 120 | Low |

---

## ğŸ”„ Data Flow & System Workflows

### **Main User Journey**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Landing  â”‚â”€â”€â”€â”€â–¶â”‚ Mode Select  â”‚â”€â”€â”€â”€â–¶â”‚ Conversation â”‚â”€â”€â”€â”€â–¶â”‚ Analysis â”‚
â”‚  Screen  â”‚     â”‚ (Chat/       â”‚     â”‚ (Live Voice) â”‚     â”‚  Results â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  Immersive)  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                             â”‚
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ End Session    â”‚
                                    â”‚ (Min 2 msgs)   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Workflow 1: Voice Conversation**

```
1. User clicks "Try it Free" â†’ app/page.tsx sets screen to "modeSelection"

2. User selects mode (Chat/Immersive) â†’ screen changes to "conversation"

3. LiveChatConversation component renders â†’ Calls useElevenLabsConversation hook

4. Hook flow:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ useElevenLabsConversation Hook Lifecycle                â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ 1. Request microphone permission                        â”‚
   â”‚ 2. Fetch signed URL from /api/elevenlabs-signed-url    â”‚
   â”‚ 3. Call conversation.startSession({ signedUrl })        â”‚
   â”‚ 4. ElevenLabs WebRTC connection established             â”‚
   â”‚ 5. Listen to events:                                    â”‚
   â”‚    - onConnect: Set isConnecting = false                â”‚
   â”‚    - onMessage: Add to messages array                   â”‚
   â”‚      â€¢ User speaks â†’ addUserMessage(content)            â”‚
   â”‚      â€¢ AI responds â†’ updateAgentMessage(content)        â”‚
   â”‚    - onDisconnect: Trigger analysis after 100ms delay   â”‚
   â”‚ 6. User clicks "End & Analyze" â†’ handleEndSession()     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. Session ends â†’ onEndSession(messages) callback fires

6. app/page.tsx receives messages â†’ Validates minimum 2 user messages

7. If valid â†’ convertToApiFormat() â†’ POST to /api/conversation-analysis

8. Screen changes to "analysis" (loading state)

9. API returns results â†’ Display ConversationAnalysisScreen
```

### **Workflow 2: Conversation Analysis**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User ends call  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ app/page.tsx                    â”‚
â”‚ handleEndSession(messages)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Filter user messages         â”‚
â”‚ 2. Check MIN_MESSAGES (2)       â”‚
â”‚ 3. convertToApiFormat()         â”‚
â”‚ 4. POST /api/conversation-      â”‚
â”‚    analysis                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ /api/conversation-analysis/route.ts â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Validate request body             â”‚
â”‚ 2. Check GEMINI_API_KEY exists       â”‚
â”‚ 3. Call analyzeConversation()        â”‚
â”‚    service                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ gemini.service.ts               â”‚
â”‚ analyzeConversation()           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Format conversation          â”‚
â”‚    transcript                   â”‚
â”‚ 2. Insert into prompt template â”‚
â”‚ 3. Call Gemini API              â”‚
â”‚ 4. Parse JSON response          â”‚
â”‚ 5. Return structured analysis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Response Structure:             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ {                               â”‚
â”‚   sentenceAnalysis: [],         â”‚
â”‚   overallStrengths: [],         â”‚
â”‚   areasToImprove: [],           â”‚
â”‚   vocabularySuggestions: [],    â”‚
â”‚   summary: "..."                â”‚
â”‚ }                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConversationAnalysisScreen      â”‚
â”‚ Displays results with icons,   â”‚
â”‚ colors, and actionable feedback â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Component Architecture

### **Component Hierarchy**

```
app/page.tsx (Root State Machine)
â”‚
â”œâ”€ HeroLanding
â”‚  â””â”€ Button: "Try it Free"
â”‚
â”œâ”€ ModeSelectionModal
â”‚  â”œâ”€ Button: "Chat Mode"
â”‚  â””â”€ Button: "Immersive Mode"
â”‚
â”œâ”€ LiveChatConversation
â”‚  â”œâ”€ useElevenLabsConversation (hook)
â”‚  â””â”€ (Conditional Render)
â”‚     â”œâ”€ ChatModeView
â”‚     â”‚  â”œâ”€ Avatar (animated)
â”‚     â”‚  â”œâ”€ Message bubbles
â”‚     â”‚  â”œâ”€ ConnectionStatusBadge (shared)
â”‚     â”‚  â””â”€ Mute button
â”‚     â”‚
â”‚     â””â”€ ImmersiveModeView
â”‚        â”œâ”€ Fullscreen videos (idle/listening/speaking)
â”‚        â””â”€ ConnectionStatusBadge (shared)
â”‚
â””â”€ ConversationAnalysisScreen
   â”œâ”€ AnalysisLoadingScreen (shared)
   â”‚  â”œâ”€ Animated spinner
   â”‚  â””â”€ Progress indicators
   â”‚
   â””â”€ Results Display
      â”œâ”€ Summary Card
      â”œâ”€ Strengths List
      â”œâ”€ Sentence Analysis (detailed)
      â”œâ”€ Areas to Improve
      â””â”€ Vocabulary Suggestions
```

### **Component Responsibilities**

| Component | Responsibility | Props | State |
|-----------|---------------|-------|-------|
| **HeroLanding** | Initial screen with CTA | `onStartPractice` | None |
| **ModeSelectionModal** | Mode selection UI | `onSelectMode`, `onCancel` | None |
| **LiveChatConversation** | Conversation wrapper | `onEndSession`, `subMode` | `micMuted` |
| **ChatModeView** | Chat UI with messages | Messages, status, handlers | None (presentational) |
| **ImmersiveModeView** | Fullscreen avatar UI | Status, handlers | Video refs |
| **ConversationAnalysisScreen** | Display feedback | Analysis data, `onBack`, `isLoading` | None |
| **ConnectionStatusBadge** | Status indicator | `status`, `label?` | None |
| **Avatar** | Animated avatar | `state`, `size` | None |

### **Shared Components**

#### `ConnectionStatusBadge`
**Purpose:** Display connection status with visual indicator

**Usage:**
```tsx
<ConnectionStatusBadge 
  status={connectionStatus} 
  label="Listening..." 
/>
```

**Benefits:**
- DRY: Used in both Chat and Immersive modes
- Consistent styling across app
- Easy to update in one place

#### `AnalysisLoadingScreen`
**Purpose:** Show loading animation while analyzing conversation

**Benefits:**
- Separated from main analysis screen
- Independent animations
- Better code organization

---

## ğŸ›ï¸ State Management

### **App-Level State** (`app/page.tsx`)

```typescript
// Screen navigation state machine
const [currentScreen, setCurrentScreen] = useState<AppScreen>("landing")

// Conversation mode
const [subMode, setSubMode] = useState<"chat" | "immersive" | null>(null)

// Analysis results
const [conversationAnalysisData, setConversationAnalysisData] = 
  useState<ConversationAnalysis | null>(null)

// Loading state
const [isGeneratingAnalysis, setIsGeneratingAnalysis] = useState(false)
```

### **Hook-Level State** (`useElevenLabsConversation`)

```typescript
// Message history (displayed in UI)
const [messages, setMessages] = useState<Message[]>([])

// Connection state
const [isConnecting, setIsConnecting] = useState(true)
const [error, setError] = useState<string | null>(null)

// Refs for sync between callbacks
const messageHistoryRef = useRef<Message[]>([])
const sessionEndedRef = useRef(false)
```

### **Why Refs Instead of State?**

```typescript
// âŒ Problem: State updates are async
sessionEndedRef.current = true  // â† Immediate
hasEndedRef.current = true      // â† Immediate

// âœ… Solution: Refs for sync access in callbacks
if (!sessionEndedRef.current) {
  // Prevents double-triggering
}
```

### **State Update Patterns**

#### **Optimistic Updates**
```typescript
// Agent messages update immediately as they stream
const updateAgentMessage = (content: string) => {
  setMessages(prev => {
    const lastMsg = getLastItem(prev)
    if (lastMsg && lastMsg.role === "agent") {
      // Update existing message (streaming)
      return [...prev.slice(0, -1), { ...lastMsg, content }]
    }
    // Add new message
    return [...prev, newAgentMessage]
  })
}
```

#### **Callback Props Pattern**
```typescript
// Parent controls state, child triggers updates
<LiveChatConversation 
  onEndSession={(messages) => {
    setConversationAnalysisData(null) // Reset
    // Trigger analysis...
  }}
/>
```

---

## ğŸŒ API Routes & Services

### **API Routes**

#### **1. POST `/api/conversation-analysis`**

**Purpose:** Analyze conversation and return detailed feedback

**Request:**
```typescript
{
  conversationHistory: ConversationMessage[] // Array of {role, content, timestamp}
}
```

**Response:**
```typescript
{
  sentenceAnalysis: SentenceAnalysis[]
  overallStrengths: string[]
  areasToImprove: AreaToImprove[]
  vocabularySuggestions: VocabSuggestion[]
  summary: string
}
```

**Flow:**
```typescript
1. Validate request body
2. Check GEMINI_API_KEY exists
3. Call analyzeConversation(history, apiKey)
4. Return JSON response
5. On error: Return FALLBACK_FEEDBACK
```

**Error Handling:**
- Always returns 200 OK with fallback data
- Never exposes internal errors to client
- Logs errors for debugging

---

#### **2. GET `/api/elevenlabs-signed-url`**

**Purpose:** Generate signed URL for ElevenLabs WebRTC connection

**Request:** None

**Response:**
```typescript
{
  signedUrl: string // Valid for ~10 minutes
}
```

**Flow:**
```typescript
1. Validate env vars (ELEVENLABS_API_KEY, AGENT_ID)
2. Call getSignedUrl(agentId, apiKey) service
3. Return signed URL to client
4. Client uses URL to initiate WebRTC connection
```

**Security:**
- API key never sent to client
- Signed URLs expire quickly
- Agent ID is public (safe)

---

### **Service Layer**

#### **gemini.service.ts**

```typescript
export async function analyzeConversation(
  conversationHistory: ConversationMessage[],
  apiKey: string
): Promise<ConversationAnalysis>
```

**Responsibilities:**
1. Format conversation into readable transcript
2. Insert transcript into prompt template
3. Call Gemini API with structured config
4. Parse JSON response
5. Handle errors gracefully

**Configuration:**
```typescript
{
  model: 'gemini-2.0-flash-exp',
  maxOutputTokens: 2048,
  temperature: 0.7,
  responseMimeType: 'application/json' // â† Forces JSON output
}
```

---

#### **elevenlabs.service.ts**

```typescript
export async function getSignedUrl(
  agentId: string,
  apiKey: string
): Promise<string>
```

**Responsibilities:**
1. Make authenticated request to ElevenLabs API
2. Extract signed URL from response
3. Handle HTTP errors

**API Endpoint:**
```
GET https://api.elevenlabs.io/v1/convai/conversation/get-signed-url?agent_id={agentId}
Headers: { "xi-api-key": apiKey }
```

---

#### **conversation.service.ts**

```typescript
export function formatConversationTranscript(
  history: ConversationMessage[]
): string

export function convertToApiFormat(
  messages: Message[]
): ConversationMessage[]
```

**Purpose:** Transform message formats between different parts of the system

**Example:**
```typescript
// Frontend format (for display)
{ role: "agent", content: "Hello", timestamp: Date }

// â†“ convertToApiFormat()

// API format (for analysis)
{ role: "assistant", content: "Hello", timestamp: Date }
```

---

## ğŸ“ Type System

### **Type Architecture**

```
lib/types/
â”œâ”€â”€ conversation.ts    # Core conversation types
â”œâ”€â”€ gemini.ts          # Gemini-specific types
â”œâ”€â”€ api.ts             # API response types
â””â”€â”€ index.ts           # Barrel exports (public API)
```

### **Core Types**

#### **Message Types**

```typescript
// Frontend message (displayed in UI)
interface Message {
  role: "user" | "agent"
  content: string
  timestamp: Date
}

// API message (sent to analysis)
interface ConversationMessage {
  role: "user" | "assistant"  // Note: "assistant" not "agent"
  content: string
  timestamp: Date
}
```

**Why Two Types?**
- `Message`: UI terminology (user sees "agent")
- `ConversationMessage`: API terminology (Gemini expects "assistant")

---

#### **Analysis Types**

```typescript
interface ConversationAnalysis {
  sentenceAnalysis: SentenceAnalysis[]
  overallStrengths: string[]
  areasToImprove: AreaToImprove[]
  vocabularySuggestions: VocabSuggestion[]
  summary: string
}

interface SentenceAnalysis {
  original: string      // What user said
  improved: string      // Better phrasing
  issues: string[]      // Problems identified
  tips: string          // Actionable advice
}

interface AreaToImprove {
  area: string          // e.g., "Pronunciation"
  explanation: string   // What to focus on
  examples: string[]    // Specific examples
}

interface VocabSuggestion {
  word: string          // New vocabulary
  meaning: string       // Definition
  example: string       // Usage example
  context: string       // When/why to use
}
```

---

#### **Config Types**

```typescript
interface GeminiModelConfig {
  name: string                    // Model identifier
  maxOutputTokens: number         // Response length limit
  temperature: number             // Creativity (0-1)
  topP?: number                   // Nucleus sampling
  topK?: number                   // Top-K sampling
  responseMimeType?: string       // Output format
}
```

---

### **Type Organization Principles**

1. **Barrel Exports** - All types exported through `index.ts`
2. **Single Source of Truth** - No duplicate type definitions
3. **Strict Typing** - No `any` types (except error boundaries)
4. **Domain Separation** - Types grouped by domain (conversation, gemini, api)

---

## ğŸ“¦ Key Dependencies

### **Production Dependencies**

| Package | Version | Purpose |
|---------|---------|---------|
| `next` | 16.x | React framework with App Router |
| `react` | 19.x | UI library |
| `typescript` | 5.x | Type safety |
| `@google/genai` | 1.31.0 | Gemini AI SDK |
| `@elevenlabs/react` | Latest | ElevenLabs voice SDK |
| `tailwindcss` | 4.x | Utility-first CSS |
| `framer-motion` | Latest | Animations |
| `clsx` + `tailwind-merge` | Latest | Conditional classes |
| `lucide-react` | Latest | Icon library |

### **Dev Dependencies**

| Package | Purpose |
|---------|---------|
| `@types/react` | React type definitions |
| `@types/node` | Node.js type definitions |
| `eslint` | Code linting |
| `postcss` | CSS processing |

### **External Services**

| Service | Purpose | Docs |
|---------|---------|------|
| **ElevenLabs Conversational AI** | Real-time voice chat | [docs.elevenlabs.io](https://docs.elevenlabs.io) |
| **Google Gemini API** | Conversation analysis | [ai.google.dev](https://ai.google.dev) |
| **Vercel** | Hosting & deployment | [vercel.com/docs](https://vercel.com/docs) |

---

## ğŸ› ï¸ Development Guidelines

### **Code Style**

#### **1. Naming Conventions**

```typescript
// Components: PascalCase
export function HeroLanding() {}

// Functions: camelCase
export function formatConversationTranscript() {}

// Constants: SCREAMING_SNAKE_CASE
export const MIN_MESSAGES_FOR_ANALYSIS = 2

// Types/Interfaces: PascalCase
interface ConversationMessage {}

// Hooks: use prefix + camelCase
export function useElevenLabsConversation() {}
```

#### **2. File Organization**

```typescript
// File structure:
// 1. Imports (grouped)
// 2. Types/Interfaces (if local to file)
// 3. Constants
// 4. Helper functions
// 5. Main component/function
// 6. Export

// Example:
import { useState } from "react"        // External
import { Button } from "@/components"   // Internal

interface Props { ... }                 // Types

const MAX_RETRY = 3                     // Constants

function helperFunction() { ... }       // Helpers

export function MainComponent() { ... } // Main export
```

#### **3. Comment Guidelines**

```typescript
// âœ… Good: Explain WHY, not WHAT
// Workaround: Small delay to allow server-side disconnect event to propagate
setTimeout(() => { ... }, ANIMATION.SESSION_END_DELAY_MS)

// âŒ Bad: States the obvious
// Set timeout to 100
setTimeout(() => { ... }, 100)

// âœ… Good: Document complex logic
// Helper: Update or add agent message (supports streaming)
const updateAgentMessage = (content: string) => { ... }

// âŒ Bad: Redundant
// Function to update agent message
const updateAgentMessage = (content: string) => { ... }
```

### **Component Guidelines**

#### **1. Component Structure**

```typescript
// âœ… Preferred structure
export function ComponentName({ prop1, prop2 }: Props) {
  // 1. Hooks
  const [state, setState] = useState()
  
  // 2. Refs
  const ref = useRef()
  
  // 3. Derived values
  const computedValue = useMemo(() => ...)
  
  // 4. Event handlers
  const handleClick = () => { ... }
  
  // 5. Effects
  useEffect(() => { ... }, [])
  
  // 6. Early returns
  if (loading) return <Loading />
  
  // 7. JSX
  return <div>...</div>
}
```

#### **2. Props Best Practices**

```typescript
// âœ… Good: Specific callback props
interface Props {
  onEndSession: (messages: Message[]) => void
  onBack: () => void
}

// âŒ Bad: Generic event handlers
interface Props {
  onClick: () => void
  onSubmit: () => void
}

// âœ… Good: Explicit required vs optional
interface Props {
  userId: string           // Required
  onUpdate?: () => void    // Optional
}
```

### **State Management Rules**

#### **1. When to Use State vs Props**

```typescript
// âœ… State: Owned by component
const [isOpen, setIsOpen] = useState(false)

// âœ… Props: Controlled by parent
<Modal isOpen={isOpen} onClose={() => setIsOpen(false)} />

// âŒ Avoid: Duplicating props in state
function Child({ value }: Props) {
  const [localValue, setLocalValue] = useState(value) // âŒ Don't do this
}
```

#### **2. When to Use Refs**

```typescript
// âœ… Refs for: DOM access, timers, sync values in callbacks
const inputRef = useRef<HTMLInputElement>(null)
const sessionEndedRef = useRef(false)

// âŒ Don't use refs for: Values that affect rendering
const countRef = useRef(0)  // âŒ Use useState instead
```

### **Error Handling**

#### **1. API Error Pattern**

```typescript
try {
  const result = await apiCall()
  return Response.json(result)
} catch (error) {
  console.error('âŒ [Context] Error:', error)
  return Response.json(FALLBACK_DATA, { status: 200 }) // â† Always 200
}
```

**Why Always 200?**
- Better UX: Users see fallback content instead of error screens
- Graceful degradation: App continues to function
- Errors logged for debugging

#### **2. Frontend Error Handling**

```typescript
// âœ… Good: Graceful degradation
const [error, setError] = useState<string | null>(null)

if (error) {
  return <ErrorMessage message={error} onRetry={retry} />
}

// âŒ Bad: Let errors crash the app
const data = await fetchData() // Uncaught promise rejection
```

### **Performance Considerations**

#### **1. Memoization**

```typescript
// âœ… Memoize expensive computations
const sortedMessages = useMemo(
  () => messages.sort((a, b) => ...),
  [messages]
)

// âœ… Memoize callbacks passed to children
const handleClick = useCallback(() => { ... }, [])
```

#### **2. Avoid Unnecessary Re-renders**

```typescript
// âœ… Extract static components
const LoadingDots = () => <div>...</div>

function Parent() {
  return loading ? <LoadingDots /> : <Content />
}

// âŒ Inline components re-create on every render
function Parent() {
  return loading ? <div>...</div> : <Content />
}
```

---

## ğŸ› Troubleshooting

### **Common Issues**

#### **1. "Type 'ConversationAnalysisData' not found"**

**Cause:** Old type name still in use  
**Fix:** Replace with `ConversationAnalysis`

```typescript
// âŒ Old
import { ConversationAnalysisData } from '@/lib/types'

// âœ… New
import { ConversationAnalysis } from '@/lib/types'
```

---

#### **2. ElevenLabs Connection Fails**

**Symptoms:** "Failed to start conversation" error

**Debug Steps:**
1. Check `ELEVENLABS_API_KEY` in `.env.local`
2. Check `NEXT_PUBLIC_ELEVENLABS_AGENT_ID` is set
3. Verify microphone permissions granted
4. Check browser console for WebRTC errors

**Common Causes:**
- Invalid API key
- Missing agent ID
- Browser blocks mic access
- Corporate firewall blocks WebRTC

---

#### **3. Gemini Analysis Returns Fallback**

**Symptoms:** Generic "Keep practicing!" feedback instead of detailed analysis

**Debug Steps:**
1. Check `GEMINI_API_KEY` in `.env.local`
2. Check terminal logs for "âŒ [Gemini Service]" errors
3. Verify at least 2 user messages sent
4. Check Gemini API quota (1500 requests/day free tier)

**Fix:**
```bash
# Check if key is loaded
echo $GEMINI_API_KEY  # Should not be empty

# Restart dev server
npm run dev
```

---

#### **4. TypeScript Errors After Update**

**Steps:**
1. Delete `.next` folder
2. Clear node_modules
3. Reinstall dependencies

```bash
rm -rf .next node_modules
npm install
npm run dev
```

---

#### **5. Session Ends Twice / Double Analysis**

**Cause:** Race condition between user action and server disconnect

**Fix:** Already handled with `sessionEndedRef` guard

```typescript
if (sessionEndedRef.current) {
  return // Prevents double-triggering
}
sessionEndedRef.current = true
```

If still occurs:
- Increase `SESSION_END_DELAY_MS` in `ui-constants.ts`

---

### **Development Tips**

#### **1. Testing Voice Conversation Locally**

```bash
# 1. Ensure env vars set
cat .env.local

# 2. Run dev server
npm run dev

# 3. Open browser with mic permissions
# Chrome: chrome://settings/content/microphone

# 4. Watch terminal logs for connection status
# Look for: âœ… Connected to ElevenLabs Agent
```

#### **2. Testing Gemini Analysis**

```bash
# Create test conversation in browser DevTools console:
const testMessages = [
  { role: "user", content: "Hello how are you", timestamp: new Date() },
  { role: "agent", content: "I'm great! How about you?", timestamp: new Date() }
]

fetch('/api/conversation-analysis', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ conversationHistory: testMessages })
}).then(r => r.json()).then(console.log)
```

#### **3. Debugging State Machine**

Add this to `app/page.tsx` for debugging:

```typescript
useEffect(() => {
  console.log('ğŸ¬ Screen:', currentScreen, '| Mode:', subMode)
}, [currentScreen, subMode])
```

#### **4. Inspecting ElevenLabs Messages**

```typescript
// In useElevenLabsConversation.ts
onMessage: (message) => {
  console.log('ğŸ“¨ Message:', JSON.stringify(message, null, 2))
  // ...
}
```

---

## ğŸ“š Additional Resources

### **Documentation Links**

- [Next.js 16 Docs](https://nextjs.org/docs)
- [Gemini AI Documentation](https://ai.google.dev/gemini-api/docs)
- [ElevenLabs Conversational AI](https://docs.elevenlabs.io/conversational-ai)
- [Tailwind CSS](https://tailwindcss.com/docs)
- [shadcn/ui](https://ui.shadcn.com/)

### **Team Contacts**

- **Frontend Lead:** [Your Name]
- **Backend Lead:** [Your Name]
- **DevOps:** [Your Name]

### **Deployment**

```bash
# Production deployment
git push origin main  # Auto-deploys to Vercel

# Preview deployment
git push origin feature-branch  # Creates preview URL
```

---

## ğŸ”„ Changelog

### **Version 1.0** (December 24, 2025)
- âœ… Initial architecture established
- âœ… Level 1 refactoring completed
- âœ… Modular structure implemented
- âœ… Shared components created
- âœ… Technical documentation written

---

**Questions?** Contact the development team or create an issue in the repository.
